{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a05064dc",
   "metadata": {},
   "source": [
    "# IMDB Review Sentiment Analysis\n",
    "\n",
    "\n",
    "Data source: https://www.kaggle.com/datasets/columbine/imdb-dataset-sentiment-analysis-in-csv-format\n",
    "\n",
    "Code adapted from: https://www.kaggle.com/code/miladlink/imdb-sentiment-analysis-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f3a59be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda install -c conda-forge spacy\n",
    "#or\n",
    "#!pip install -U pip setuptools wheel\n",
    "#!pip install -U spacy\n",
    "\n",
    "#then\n",
    "#!pip3 install https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.0.0/en_core_web_sm-3.0.0.tar.gz\n",
    "\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "import spacy\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# setup\n",
    "NLP = spacy.load('en_core_web_sm')  # NLP toolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fe8179a-2240-4610-845e-96561de6c565",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize for random seeds/states\n",
    "seeds=[12345,42,42]\n",
    "def randomize(seed_rng=seeds[0], seed_np=seeds[1], seed_torch=seeds[2]):\n",
    "    os.environ['PYTHONHASHSEED'] = '0'\n",
    "    rng = np.random.default_rng(seed_rng)\n",
    "    np.random.seed(seed_np)\n",
    "    torch.manual_seed(seed_torch)\n",
    "\n",
    "randomize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c74309",
   "metadata": {},
   "source": [
    "## Explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "021b4193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read dataset\n",
    "train_df = pd.read_csv(\"Train.csv\")\n",
    "valid_df = pd.read_csv(\"Valid.csv\")\n",
    "test_df = pd.read_csv(\"Test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2de27857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of train: 40000\n",
      "number of valid: 5000\n",
      "number of test: 5000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I grew up (b. 1965) watching and loving the Th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When I put this movie in my DVD player, and sa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why do people who do not know what a particula...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  I grew up (b. 1965) watching and loving the Th...      0\n",
       "1  When I put this movie in my DVD player, and sa...      0\n",
       "2  Why do people who do not know what a particula...      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('number of train:', len(train_df))\n",
    "print('number of valid:', len(valid_df))\n",
    "print('number of test:', len(test_df))\n",
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b404911",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/apps/flight/env/conda+jupyter/lib/python3.9/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='label', ylabel='count'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(train_df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "524f93c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/apps/flight/env/conda+jupyter/lib/python3.9/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='label', ylabel='count'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(valid_df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9734cba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/apps/flight/env/conda+jupyter/lib/python3.9/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='label', ylabel='count'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(test_df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f52f6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min length = 4\n",
      "Max length = 2470\n",
      "Mean = 231.33\n",
      "Std  = 171.18\n",
      "mean + 1 * sigma = 402.51\n"
     ]
    }
   ],
   "source": [
    "num_words = [len(f.split(' ')) for f in train_df['text']]\n",
    "\n",
    "# print statistics\n",
    "print('Min length =', min(num_words))\n",
    "print('Max length =', max(num_words))\n",
    "\n",
    "print('Mean = {:.2f}'.format(np.mean(num_words)))\n",
    "print('Std  = {:.2f}'.format(np.std(num_words)))\n",
    "\n",
    "print('mean + 1 * sigma = {:.2f}'.format(np.mean(num_words) + 1.0 * np.std(num_words)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3827e209",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2223f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_stopwords = True\n",
    "stopwords = NLP.Defaults.stop_words if use_stopwords else []\n",
    "def tokenizer(text, stopwords=stopwords):\n",
    "    text = re.sub(r\"<br /><br />\", \" \", text)\n",
    "    text = re.sub(r\"[\\*\\\"“”\\n\\\\…\\+\\-\\/\\=\\(\\)‘•:\\[\\]\\|’;]\", \" \", str(text))\n",
    "    text = re.sub(r\"[ ]+\", \" \", text)\n",
    "    text = re.sub(r\"\\!+\", \"!\", text)\n",
    "    text = re.sub(r\"\\,+\", \",\", text)\n",
    "    text = re.sub(r\"\\?+\", \"?\", text)\n",
    "    return [x.text for x in NLP.tokenizer(text) if x.text != \" \" and (x.text not in stopwords)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8f1cec2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'enough', 'out', 'very', 'thereby', 'another', 'many', 'keep', 'hence', 'a', 'n’t', 'call', 'while', '’ll', 'hereafter', 'amount', 'on', 'ca', 'former', 'seemed', 'side', 'latter', 'whose', 'themselves', \"'m\", 'hereby', 'their', 'such', 'wherever', 'how', '‘d', 'always', 'towards', 'name', 'empty', 'whenever', 'one', 'nine', \"'s\", 'yourselves', 'somewhere', 'up', 'made', 'whereby', 'his', 'upon', 'top', 'afterwards', 'here', 'than', 'sometimes', 're', 'serious', 'to', 'might', 'per', 'still', 'herein', 'more', 'never', 'back', 'at', 'them', 'your', 'unless', \"'ll\", 'once', 'everywhere', 'must', 'sometime', 'both', 'by', 'are', 'due', 'they', 'should', 'became', 'may', 'it', 'hereupon', 'few', '‘re', '’m', 'whole', 'have', 'everyone', 'this', 'did', 'ours', 'mostly', 'often', 'my', 'onto', 'him', 'between', 'seem', 'though', 'several', 'beyond', 'whereas', 'together', 'without', 'whom', 'who', 'were', 'since', 'as', 'further', 'her', 'twelve', '’s', 'already', 'nevertheless', 'whereupon', 'less', 'our', 'each', 'be', 'whatever', 'yours', 'sixty', 'within', 'beforehand', 'put', 'its', 'used', 'below', 'then', '‘ll', 'throughout', 'about', 'what', 'herself', 'namely', 'regarding', 'which', 'least', 'will', 'make', 'much', '‘s', 'been', 'next', 'well', 'seeming', 'would', 'using', 'everything', 'five', 'again', 'had', 'indeed', 'but', 'yourself', 'beside', 'could', 'therefore', 'give', 'say', 'yet', 'cannot', 'also', 'during', 'doing', 'does', 'thus', 'an', 'ever', 'across', 'every', 'for', 'so', 'although', 'rather', 'eleven', 'nobody', 'nothing', 'she', 'third', 'hers', 'perhaps', 'down', 'you', 'thereupon', 'above', 'whereafter', 'the', \"'re\", 'those', 'myself', 'formerly', 'any', \"'d\", 'when', 'via', 'not', 'now', 'until', 'whoever', 'amongst', 'against', 'someone', 'full', 'else', 'except', 'six', 'done', 'thereafter', 'anyone', 'eight', 'why', 'otherwise', 'becomes', 'fifty', 'in', 'am', 'move', 'get', 'become', 'alone', 'either', 'besides', 'anything', 'last', 'even', 'with', 'i', 'among', 'own', 'he', 'from', 'that', 'therein', '‘ve', 'around', 'whether', 'quite', '’d', 'moreover', 'off', 'along', 'can', 'four', 'we', 'thru', 'take', 'behind', 'itself', 'seems', 'twenty', 'nowhere', 'is', 'three', 'has', 'these', 'two', 'if', 'because', 'most', 'too', 'and', 'first', '‘m', '’re', 'toward', 'see', 'some', 'us', 'ourselves', 'latterly', 'elsewhere', 'before', 'whither', 'same', 'part', 'something', 'all', 'over', 'thence', 'anyway', 'neither', 'anyhow', 'whence', '’ve', 'other', 'or', 'me', 'of', 'mine', 'being', 'where', 'himself', 'noone', 'front', 'after', 'just', 'becoming', 'hundred', 'however', 'through', 'really', 'nor', 'others', 'meanwhile', 'under', 'wherein', 'bottom', 'fifteen', \"n't\", 'anywhere', 'n‘t', 'was', 'go', 'various', 'almost', 'do', 'forty', 'only', 'somehow', 'there', 'none', 'into', 'show', 'ten', \"'ve\", 'no', 'please'}\n"
     ]
    }
   ],
   "source": [
    "print(stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa98d72",
   "metadata": {},
   "source": [
    "## Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17529ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary(object):\n",
    "    \n",
    "    def __init__(self, tokenizer, stopwords=stopwords):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.stopwords = stopwords\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {}\n",
    "        self.count = 0\n",
    "    \n",
    "    def add_word(self, word):\n",
    "        if not word in self.word2index:\n",
    "            self.word2index[word] = self.count\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.count] = word\n",
    "            self.count += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "    \n",
    "    def add_sentence(self, sentence):\n",
    "        for word in self.tokenizer(sentence, self.stopwords):\n",
    "            self.add_word(word)\n",
    "            \n",
    "    def __len__(self):\n",
    "        return self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0f994a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD = '<pad>'  # special symbol we use for padding text\n",
    "UNK = '<unk>'  # special symbol we use for rare or unknown word\n",
    "CLASSES = ['negative', 'positive']\n",
    "MAX_LEN = 300     #max input length, if fewer than this, padding is added \n",
    "MIN_COUNT = 10    #if frequency rare than this the word is set as unknown\n",
    "VOCAB_PATH = 'vocab.pkl'\n",
    "BATCH_SIZE = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4ba1fd",
   "metadata": {},
   "source": [
    "## Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f523aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextClassDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, df, tokenizer, classes, vocab_path='vocab.pkl', max_len=100, min_count=10, stopwords=stopwords):\n",
    "        #assign input---------------\n",
    "        self.df = df\n",
    "        self.vocab_path = vocab_path\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.min_count = min_count\n",
    "        self.classes = classes\n",
    "        self.stopwords = stopwords\n",
    "        #---------------------------\n",
    "        self.vocab = None\n",
    "        self.class_idx = np.unique(df['label'])\n",
    "        self.class_to_index = {classes[i]: i for i in range(len(classes))}        \n",
    "        self.num_classes = len(self.classes)\n",
    "        self.text = df['text']\n",
    "        # build vocabulary from training and validation texts\n",
    "        self.build_vocab()\n",
    "        \n",
    "    def __getitem__(self, index):        \n",
    "        # read text file \n",
    "        text, label = self.df['text'][index], self.df['label'][index]\n",
    "        \n",
    "        # tokenize the text file\n",
    "        tokens = self.tokenizer(text.lower().strip(), self.stopwords)\n",
    "        \n",
    "        # padding and trimming\n",
    "        if len(tokens) < self.max_len:\n",
    "            num_pads = self.max_len - len(tokens)\n",
    "            tokens = tokens + [PAD] * num_pads \n",
    "        elif len(tokens) > self.max_len:\n",
    "            tokens = tokens[:self.max_len]\n",
    "            \n",
    "        # numericalizing\n",
    "        ids = torch.LongTensor(self.max_len)\n",
    "        for i, word in enumerate(tokens):\n",
    "            if word not in self.vocab.word2index:\n",
    "                ids[i] = self.vocab.word2index[UNK]  # unknown words\n",
    "            elif word != PAD and self.vocab.word2count[word] < self.min_count:\n",
    "                ids[i] = self.vocab.word2index[UNK]  # rare words\n",
    "            else:\n",
    "                ids[i] = self.vocab.word2index[word]\n",
    "        \n",
    "        return ids, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def build_vocab(self):\n",
    "        if not os.path.exists(self.vocab_path):\n",
    "            vocab = Vocabulary(self.tokenizer)\n",
    "            for f in self.df['text']:\n",
    "                for line in f.split('\\n'):\n",
    "                    vocab.add_sentence(line.lower())\n",
    "            # sort words by their frequencies--------\n",
    "            words = [(0, PAD), (0, UNK)]\n",
    "            words += sorted([(c, w) for w, c in vocab.word2count.items()], reverse=True)\n",
    "\n",
    "            self.vocab = Vocabulary(self.tokenizer)\n",
    "            for i, (count, word) in enumerate(words):\n",
    "                self.vocab.word2index[word] = i\n",
    "                self.vocab.word2count[word] = count\n",
    "                self.vocab.index2word[i] = word\n",
    "                self.vocab.count += 1\n",
    "            \n",
    "            pickle.dump(self.vocab, open(self.vocab_path, 'wb'))\n",
    "        else:\n",
    "            self.vocab = pickle.load(open(self.vocab_path, 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94dc0f2",
   "metadata": {},
   "source": [
    "### Set dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15bf038e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TextClassDataset(train_df, tokenizer, CLASSES, VOCAB_PATH, MAX_LEN, MIN_COUNT, stopwords)\n",
    "valid_ds = TextClassDataset(valid_df, tokenizer, CLASSES, VOCAB_PATH, MAX_LEN, MIN_COUNT, stopwords)\n",
    "test_ds = TextClassDataset(test_df, tokenizer, CLASSES, VOCAB_PATH, MAX_LEN, MIN_COUNT, stopwords)\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_dl = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd46418",
   "metadata": {},
   "source": [
    "## Explore data after processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f3eb060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text shape: torch.Size([300])\n",
      "text shape: ()\n",
      "number of texts: 40000\n",
      "['negative', 'positive']\n",
      "{'negative': 0, 'positive': 1}\n"
     ]
    }
   ],
   "source": [
    "print('text shape:', train_ds[0][0].shape)\n",
    "print('text shape:', train_ds[0][1].shape)\n",
    "print('number of texts:', len(train_ds))\n",
    "print(train_ds.classes)\n",
    "print(train_ds.class_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ea01c2e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movie dvd player , sat coke chips , expectations . hoping movie contain strong points movie awsome animation , good flowing story , excellent voice cast , funny comedy kick ass soundtrack . , disappointment , found atlantis milo return . read reviews , let . following paragraph directed seen movie , enjoyed primarily points mentioned . scene appears , shock picked atlantis milo return display case local <unk> , expectations . music feels bad imitation movie , voice cast replaced fitting . exception characters , like voice sweet . actual drawings nt bad , animation particular sad sight . storyline pretty weak , like episodes <unk> doo single adventurous story got time . nt misunderstand , good <unk> doo episodes . nt laugh single time , <unk> twice . audience seen movie , especially care similar sequel , fast review movie stand product liked <unk> doo , like movie . , enjoy movie . suspect good kids movie , know . better milo return episode series cartoon channel , breakfast tv . <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n"
     ]
    }
   ],
   "source": [
    "# convert back the sequence of integers into original text\n",
    "print(' '.join([train_ds.vocab.index2word[i.item()] for i in train_ds[1][0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c724f2d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When I put this movie in my DVD player, and sat down with a coke and some chips, I had some expectations. I was hoping that this movie would contain some of the strong-points of the first movie: Awsome animation, good flowing story, excellent voice cast, funny comedy and a kick-ass soundtrack. But, to my disappointment, not any of this is to be found in Atlantis: Milo's Return. Had I read some reviews first, I might not have been so let down. The following paragraph will be directed to those who have seen the first movie, and who enjoyed it primarily for the points mentioned.<br /><br />When the first scene appears, your in for a shock if you just picked Atlantis: Milo's Return from the display-case at your local videoshop (or whatever), and had the expectations I had. The music feels as a bad imitation of the first movie, and the voice cast has been replaced by a not so fitting one. (With the exception of a few characters, like the voice of Sweet). The actual drawings isnt that bad, but the animation in particular is a sad sight. The storyline is also pretty weak, as its more like three episodes of Schooby-Doo than the single adventurous story we got the last time. But dont misunderstand, it's not very good Schooby-Doo episodes. I didnt laugh a single time, although I might have sniggered once or twice.<br /><br />To the audience who haven't seen the first movie, or don't especially care for a similar sequel, here is a fast review of this movie as a stand-alone product: If you liked schooby-doo, you might like this movie. If you didn't, you could still enjoy this movie if you have nothing else to do. And I suspect it might be a good kids movie, but I wouldn't know. It might have been better if Milo's Return had been a three-episode series on a cartoon channel, or on breakfast TV.\n"
     ]
    }
   ],
   "source": [
    "# print the original text\n",
    "print(train_ds.text[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b437636b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size = 25206\n",
      "\n",
      "Most common words:\n",
      ".: 437232\n",
      ",: 435318\n",
      "movie: 70331\n",
      "film: 63527\n",
      "like: 32272\n",
      "!: 30453\n",
      "': 27010\n",
      "good: 23858\n",
      "?: 23680\n",
      "time: 20108\n"
     ]
    }
   ],
   "source": [
    "vocab = train_ds.vocab\n",
    "freqs = [(count, word) for (word, count) in vocab.word2count.items() if count >= MIN_COUNT]\n",
    "vocab_size = len(freqs) + 2  # for PAD and UNK tokens\n",
    "print(f'Vocab size = {vocab_size}')\n",
    "\n",
    "print('\\nMost common words:')\n",
    "for c, w in sorted(freqs, reverse=True)[:10]:\n",
    "    print(f'{w}: {c}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988cbada",
   "metadata": {},
   "source": [
    "## Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "86de485e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention computes a weighted average of the hidden states of the LSTM Model.\n",
    "# In fact, it produce a weight for each hidden state at different time steps\n",
    "\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.projection = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, 64),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "    def forward(self, encoder_outputs):\n",
    "        # encoder_outputs = [batch size, sent len, hid dim]\n",
    "        energy = self.projection(encoder_outputs)\n",
    "        # energy = [batch size, sent len, 1]\n",
    "        weights = F.softmax(energy.squeeze(-1), dim=1)\n",
    "        # weights = [batch size, sent len]\n",
    "        outputs = (encoder_outputs * weights.unsqueeze(-1)).sum(dim=1)\n",
    "        # outputs = [batch size, hid dim]\n",
    "        return outputs, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fc02667f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional, dropout):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.num_layers = n_layers\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=n_layers,\n",
    "                            bidirectional=bidirectional, \n",
    "                            dropout= 0 if n_layers < 2 else dropout)\n",
    "        self.attention = SelfAttention(hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x = [sent len, batch size]\n",
    "        embedded = self.embedding(x)\n",
    "        # embedded = [sent len, batch size, emb dim]\n",
    "        output, (hidden, cell) = self.lstm(embedded)\n",
    "        # use 'batch_first' if you want batch size to be the 1st para\n",
    "        # output = [sent len, batch size, hid dim*num directions]\n",
    "        output = output[:, :, :self.hidden_dim] + output[:, :, self.hidden_dim:]\n",
    "        # output = [sent len, batch size, hid dim]\n",
    "        ouput = output.permute(1, 0, 2)\n",
    "        # ouput = [batch size, sent len, hid dim]\n",
    "        new_embed, weights = self.attention(ouput)\n",
    "        # new_embed = [batch size, hid dim]\n",
    "        # weights = [batch size, sent len]\n",
    "        new_embed = self.dropout(new_embed)\n",
    "        return self.fc(new_embed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c15fc05",
   "metadata": {},
   "source": [
    "## Training helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e6dfe5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one(model, loader, loss_fn, optimizer, metric_fn, device):\n",
    "    \"\"\" training one epoch and calculate loss and metrics \"\"\"\n",
    "    # Training model\n",
    "    model.train()\n",
    "    losses = 0.0\n",
    "    metrics = 0.0\n",
    "    steps = len(loader)\n",
    "\n",
    "    for i, (inputs, labels) in enumerate(loader):\n",
    "        # Place to gpu\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        model.zero_grad()\n",
    "        outputs = model(inputs.t())\n",
    "        # Calculate loss\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        losses += loss\n",
    "        # Backpropagation and update weights\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.3)\n",
    "        optimizer.step()\n",
    "        # Calculate metrics\n",
    "        metric = metric_fn(outputs, labels)\n",
    "        metrics += metric\n",
    "        # report\n",
    "        sys.stdout.flush()\n",
    "        sys.stdout.write('\\r Step: [%2d/%2d], loss: %.4f - acc: %.4f' % (i, steps, loss.item(), metric))\n",
    "    \n",
    "    sys.stdout.write ('\\r')\n",
    "    return losses.item() / len(loader), metrics / len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c36e5558",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    \"\"\" calculate percent of true labels \"\"\"\n",
    "    # predicted labels\n",
    "    _, preds = torch.max(outputs, dim = 1)\n",
    "    return torch.sum(preds == labels).item() / len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a4831cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader, loss_fn, metric_fn, device):\n",
    "    \"\"\" Evaluate trained weights using calculate loss and metrics \"\"\"\n",
    "    # Evaluate model\n",
    "    model.eval()\n",
    "    losses = 0.0\n",
    "    metrics = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs.t())\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            losses += loss\n",
    "            metrics += metric_fn(outputs, labels)\n",
    "    return losses.item() / len(loader), metrics / len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9333a6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_dl, valid_dl, loss_fn, optimizer, num_epochs, metric_fn, device, checkpoint_path, scheduler=None, load_model=False, prev_best_loss=None):\n",
    "    \"\"\" fiting model to dataloaders, saving best weights and showing results \"\"\"\n",
    "    # to continue training from saved weights\n",
    "    if load_model:\n",
    "        load_checkpoint(torch.load(checkpoint_path), model)\n",
    "    if prev_best_loss is None:\n",
    "        best_loss = 1000000\n",
    "    else:\n",
    "        best_loss = prev_best_loss\n",
    "    losses, val_losses, accs, val_accs = [], [], [], []\n",
    "    since = time.time()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        loss, acc = train_one(model, train_dl, loss_fn, optimizer, metric_fn, device)\n",
    "        val_loss, val_acc = evaluate (model, valid_dl, loss_fn, metric_fn, device)\n",
    "        losses.append(loss)\n",
    "        accs.append(acc)\n",
    "        val_losses.append(val_loss)\n",
    "        val_accs.append(val_acc)\n",
    "        # learning rate scheduler------\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "        # save weights if improved-----\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            best_wts = model.state_dict().copy()\n",
    "            torch.save(best_wts, checkpoint_path)\n",
    "            print('Checkpoint Saved! Epoch {} is better.***************************'.format(epoch+1))\n",
    "        print('Epoch [{}/{}], loss: {:.4f} - acc: {:.4f} - val_loss: {:.4f} - val_acc: {:.4f}'.format (epoch + 1, num_epochs, loss, acc, val_loss, val_acc))\n",
    "\n",
    "    period = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format (period // 60, period % 60))\n",
    "    model.load_state_dict(best_wts)\n",
    "    return dict(loss = losses, val_loss = val_losses, acc = accs, val_acc = val_accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39bd1958",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "990f324a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "03f25429-ff2c-4b3a-87c9-b424a661a5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM parameters\n",
    "EMBED_SIZE = 256\n",
    "HIDDEN_SIZE = 1024\n",
    "NUM_LAYERS = 1\n",
    "\n",
    "# training parameters\n",
    "LR = 0.001\n",
    "NUM_EPOCHS = 2\n",
    "CHECKPOINT_PATH = 'IMDB_Normal.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "464a5f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AttentionLSTM(vocab_size, EMBED_SIZE, HIDDEN_SIZE, train_ds.num_classes, NUM_LAYERS, bidirectional=True, dropout=0.5).to(DEVICE)\n",
    "loss_fn = nn.CrossEntropyLoss().to(DEVICE)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR, betas=(0.7, 0.99))\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7d7a108c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint Saved! Epoch 1 is better.***************************\n",
      "Epoch [1/2], loss: 0.3999 - acc: 0.8146 - val_loss: 0.2825 - val_acc: 0.8784\n",
      "Epoch [2/2], loss: 0.2176 - acc: 0.9169 - val_loss: 0.2867 - val_acc: 0.8946\n",
      "Training complete in 5m 20s\n"
     ]
    }
   ],
   "source": [
    "history = train(model, train_dl, valid_dl, loss_fn, optimizer, NUM_EPOCHS, accuracy, DEVICE, CHECKPOINT_PATH, scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73af98c9",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "40516018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(CHECKPOINT_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6bf13725",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.29209945678710936, 0.8821999999999997)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(model, test_dl, loss_fn, accuracy, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2077028f-f331-47a3-84e5-444a0093fb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_base(BATCH_SIZE, MAX_LEN, MIN_COUNT, stopwords=stopwords, NUM_EPOCHS=2):\n",
    "    train_ds = TextClassDataset(train_df, tokenizer, CLASSES, VOCAB_PATH, MAX_LEN, MIN_COUNT, stopwords)\n",
    "    valid_ds = TextClassDataset(valid_df, tokenizer, CLASSES, VOCAB_PATH, MAX_LEN, MIN_COUNT, stopwords)\n",
    "    test_ds = TextClassDataset(test_df, tokenizer, CLASSES, VOCAB_PATH, MAX_LEN, MIN_COUNT, stopwords)\n",
    "\n",
    "    train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    valid_dl = DataLoader(valid_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    test_dl = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    model = AttentionLSTM(vocab_size, EMBED_SIZE, HIDDEN_SIZE, train_ds.num_classes, NUM_LAYERS, bidirectional=True, dropout=0.5).to(DEVICE)\n",
    "    loss_fn = nn.CrossEntropyLoss().to(DEVICE)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LR, betas=(0.7, 0.99))\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.9)\n",
    "    \n",
    "    randomize()\n",
    "    history = train(model, train_dl, valid_dl, loss_fn, optimizer, NUM_EPOCHS, accuracy, DEVICE, CHECKPOINT_PATH, scheduler)\n",
    "    return history, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "163031a2-c675-424a-99ea-4836d4c2a0ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint Saved! Epoch 1 is better.***************************\n",
      "Epoch [1/2], loss: 0.3688 - acc: 0.8365 - val_loss: 0.3114 - val_acc: 0.8640\n",
      "Checkpoint Saved! Epoch 2 is better.***************************\n",
      "Epoch [2/2], loss: 0.2122 - acc: 0.9206 - val_loss: 0.2814 - val_acc: 0.8970\n",
      "Training complete in 5m 9s\n"
     ]
    }
   ],
   "source": [
    "history, model = gen_base(BATCH_SIZE, MAX_LEN, MIN_COUNT, NUM_EPOCHS=NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff1dd1d-fa7a-42a0-8dba-d1926a27dea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS=2\n",
    "history={}\n",
    "model={}\n",
    "#torch.Backends.Cudnn.Enabled = False\n",
    "for BATCH_SIZE in [16, 25, 50]:\n",
    "    for MAX_LEN in [300, 400, 500]:\n",
    "        for MIN_COUNT in [10, 20]:\n",
    "            print('BATCH_SIZE: {}; MAX_LEN: {}; MIN_COUNT: {}'.format(BATCH_SIZE, MAX_LEN, MIN_COUNT),'------------------------------------------')\n",
    "            key = 'b'+str(BATCH_SIZE)+'max'+str(MAX_LEN)+'min'+str(MIN_COUNT)\n",
    "            history[key], model[key] = gen_base(BATCH_SIZE, MAX_LEN, MIN_COUNT, NUM_EPOCHS=NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e8fa40",
   "metadata": {},
   "source": [
    "### confusion matrix, plot to be made..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5871b432",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cac5f104",
   "metadata": {},
   "source": [
    "###  explore some wrong predictions..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c68a80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
